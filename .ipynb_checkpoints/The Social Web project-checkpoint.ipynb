{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Social Web project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this small project, we want to analyze the correlations between 'consipracy thinkers' on Twitter. We will look at certain hashtags that are likely correlated with consipracy theories in the Netherlands. In this notebook we will present all the steps that we have taken to find an answer to our research questions: \n",
    "\n",
    "1. Which words cause people to be more vulnerable to believe conspiracy theories?\n",
    "2. How deeply clustered are conspiracy hashtags compared to regular hashtags?\n",
    "3. What kind of hashtags are likely to be related to conspiracy theories?\n",
    "4. How can we deal with misinformation on social media?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will install some packages to run all of our steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This jupyter notebook is running on Python 3.8.6\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "print(\"This jupyter notebook is running on Python \" + platform.python_version())\n",
    "# It's good practice to assert packages requirements at the beginning of a script:\n",
    "assert sys.version_info >= (3, 6) # Tested with Python==3.7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-100-a3f1d231f5b3>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-100-a3f1d231f5b3>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    python -m spacy download nl\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip3 install twitter PrettyTable matplotlib\n",
    "!pip3 install requests\n",
    "!pip3 install BeautifulSoup4\n",
    "!pip3 install HTMLParser\n",
    "!pip3 install rdflib\n",
    "!pip3 install tweepy\n",
    "!pip3 install spacy\n",
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'nl_core_news_sm' from 'spacy' (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/spacy/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-486416f44646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnl_core_news_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'nl_core_news_sm' from 'spacy' (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/spacy/__init__.py)"
     ]
    }
   ],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from string import punctuation\n",
    "import collections\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from spacy import nl_core_news_sm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in assignment 1 of the notebooks, we will import several hastags from Twitter. We firstly need to implement some Twitter API keys to make this possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter credentials\n",
    "# Obtain them from your twitter developer account\n",
    "consumer_key = 'N4J4jiQuGW7DZKLvUXg1DUYlw'\n",
    "consumer_secret = 'HwhmSr8rGqbzG9NlfaOSHl4No2RijgtJwtDCQEFNZ5vlSPzYbj'\n",
    "access_key = '158063657-YJjxwBnlFS6GGn0jkhnqA6PIjzVRC9UhACSjCWrX'\n",
    "access_secret = 'kuwpm8QnoNIX3bTkgOrlhjbdEKYxRiFqxqRXXRdLGeoJF'\n",
    "# Pass your twitter credentials to tweepy via its OAuthHandler\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lets take a look at some hashtags we see as consipracy believers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project we will look at the keyword: Viruswaarheid. This is a group that believes the Coronavirus is a hoax and that politicians are a group of pedophiles. \n",
    "\n",
    "Next to this we also want to find more information about the Young Forum for Democracy party which has been quite a lot in the media concerning antisemtism and consipricacy theories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first perform a scrape on Twitter and add the information in a CSV file. This file can be used in a later stage to analyze. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>description</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>viruswaarheid</td>\n",
       "      <td>3269</td>\n",
       "      <td>109</td>\n",
       "      <td>@viruswaanzin gaat verder als @viruswaarheid\\n...</td>\n",
       "      <td>2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>viruswaarheid</td>\n",
       "      <td>3269</td>\n",
       "      <td>109</td>\n",
       "      <td>@viruswaanzin gaat verder als @viruswaarheid\\n...</td>\n",
       "      <td>2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanBe00194645</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The end cannot justify the means, for the simp...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>volger4444</td>\n",
       "      <td>23</td>\n",
       "      <td>136</td>\n",
       "      <td></td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v4vendettaNL</td>\n",
       "      <td>32</td>\n",
       "      <td>62</td>\n",
       "      <td></td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name  followers  friends  \\\n",
       "0    viruswaarheid       3269      109   \n",
       "1    viruswaarheid       3269      109   \n",
       "2  HumanBe00194645          1        2   \n",
       "3       volger4444         23      136   \n",
       "4     v4vendettaNL         32       62   \n",
       "\n",
       "                                         description  tweets  \n",
       "0  @viruswaanzin gaat verder als @viruswaarheid\\n...    2230  \n",
       "1  @viruswaanzin gaat verder als @viruswaarheid\\n...    2230  \n",
       "2  The end cannot justify the means, for the simp...     420  \n",
       "3                                                        702  \n",
       "4                                                        638  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweepy.Cursor(api.search,q = 'Viruswaarheid', since_id = '2020-01-01').items(2000)\n",
    "users = []\n",
    "followers = []\n",
    "friends = []\n",
    "description = []\n",
    "tweet_count = []\n",
    "for status in tweets:\n",
    "    name = status.user.screen_name\n",
    "    desc = status.user.description\n",
    "    number_of_tweets = status.user.statuses_count\n",
    "    following = status.user.friends_count\n",
    "    follower = status.user.followers_count\n",
    "    users.append(name)\n",
    "    followers.append(follower)\n",
    "    friends.append(following)\n",
    "    description.append(desc)\n",
    "    tweet_count.append(number_of_tweets) \n",
    "\n",
    "data = {'screen_name':users, 'followers':followers, 'friends':friends, 'description':description, 'tweets':tweet_count}\n",
    "df_8 = pd.DataFrame(data)\n",
    "    \n",
    "#     df['screen_name'] = users\n",
    "#     df['location'] = location\n",
    "    \n",
    "df_8.to_csv('Viruswaarheid.csv')\n",
    "df_8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create two files with tweets about #Viruswaarheid (conspiracy theory) and on the other hand a 'regular' hashtag named #Goedemorgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Viruswaarheid-tweets.csv', 'w', newline='') as outcsv:\n",
    "    writer = csv.writer(outcsv)\n",
    "    writer.writerow([\"ID\", \"Tweets\"])\n",
    "    for tweet in tweepy.Cursor(api.search,q=\"#Viruswaarheid\",count=10000,\n",
    "                           lang=\"nl\",\n",
    "                           since=\"2020-01-01\").items():\n",
    "        writer.writerow([tweet.id, tweet.text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Goedemorgen-tweets.csv', 'w', newline='') as outcsv:\n",
    "    writer = csv.writer(outcsv)\n",
    "    writer.writerow([\"ID\", \"Tweets\"])\n",
    "    for tweet in tweepy.Cursor(api.search,q=\"#Goedemorgen\",count=10000,\n",
    "                           lang=\"nl\",\n",
    "                           since=\"2020-01-01\").items():\n",
    "        writer.writerow([tweet.id, tweet.text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viruswaarheid_tweets = pd.read_csv('Viruswaarheid-tweets.csv')\n",
    "Goedemorgen_tweets = pd.read_csv('Goedemorgen-tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform some cleaning of the data, where we will use lemmatization, tokenizing, removing stopwards, punctuations, hashtags and mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1336408457101062151</td>\n",
       "      <td>bgoh sommige volgers van viruswaarheid stopwil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1336384037661904897</td>\n",
       "      <td>bviruswaarheid wakeup riseup hoe houd rutte di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1336363907112460292</td>\n",
       "      <td>b82 dansen met willem engel n via  nnengel vir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336255744967110658</td>\n",
       "      <td>b   okee dus op viruswaarheid nnja denk het ei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1336054169493512192</td>\n",
       "      <td>brt   b tijdrekken kan alleen als er gewacht w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                             Tweets\n",
       "0  1336408457101062151  bgoh sommige volgers van viruswaarheid stopwil...\n",
       "1  1336384037661904897  bviruswaarheid wakeup riseup hoe houd rutte di...\n",
       "2  1336363907112460292  b82 dansen met willem engel n via  nnengel vir...\n",
       "3  1336255744967110658  b   okee dus op viruswaarheid nnja denk het ei...\n",
       "4  1336054169493512192  brt   b tijdrekken kan alleen als er gewacht w..."
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    return df\n",
    "\n",
    "clean_tweets_Viruswaarheid = clean_text(Viruswaarheid_tweets, 'Tweets')\n",
    "clean_tweets_Viruswaarheid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1336593342864486400</td>\n",
       "      <td>bgoede morgen tweepsff vraagje vinden jullie d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1336589481063878656</td>\n",
       "      <td>bis het heel erg als nu al roep dat het bijna ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1336588545117523970</td>\n",
       "      <td>bgoedemorgen deze woensdag nlekker hoor die it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336588395838124033</td>\n",
       "      <td>bgoedemorgen allemaal een mooie woensdag gewen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1336587131817496577</td>\n",
       "      <td>bgoedemorgen mensen ik zie weinig vandaag mist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                             Tweets\n",
       "0  1336593342864486400  bgoede morgen tweepsff vraagje vinden jullie d...\n",
       "1  1336589481063878656  bis het heel erg als nu al roep dat het bijna ...\n",
       "2  1336588545117523970  bgoedemorgen deze woensdag nlekker hoor die it...\n",
       "3  1336588395838124033  bgoedemorgen allemaal een mooie woensdag gewen...\n",
       "4  1336587131817496577  bgoedemorgen mensen ik zie weinig vandaag mist..."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    return df\n",
    "\n",
    "clean_tweets_Goedemorgen = clean_text(Goedemorgen_tweets, 'Tweets')\n",
    "clean_tweets_Goedemorgen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop = set(stopwords.words('dutch'))\n",
    "punctuation = list(string.punctuation) #already taken care of with the cleaning function.\n",
    "stop.update(punctuation)\n",
    "w_tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "            \n",
    "def furnished(text):\n",
    "    final_text = []\n",
    "    for i in w_tokenizer.tokenize(text):\n",
    "#     for i in text.split():\n",
    "        if i.lower() not in stop:\n",
    "            word = lemmatizer.lemmatize(i)\n",
    "            final_text.append(word.lower())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "\n",
    "            \n",
    "tweets_bowl.tweets = tweets_bowl.tweets.apply(furnished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation) #already taken care of with the cleaning function.\n",
    "stop.update(punctuation)\n",
    "w_tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "            \n",
    "def furnished(text):\n",
    "    final_text = []\n",
    "    for i in w_tokenizer.tokenize(text):\n",
    "#     for i in text.split():\n",
    "        if i.lower() not in stop:\n",
    "            word = lemmatizer.lemmatize(i)\n",
    "            final_text.append(word.lower())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "\n",
    "            \n",
    "Goedemorgen_tweets.tweets = Goedemorgen_tweets.tweets.apply(furnished)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
